{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor, Dinov2Model\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"huggingface/cats-image\")\n",
    "image = dataset[\"test\"][\"image\"][0]\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"facebook/dinov2-base\")\n",
    "model = Dinov2Model.from_pretrained(\"facebook/dinov2-base\")\n",
    "\n",
    "inputs = image_processor([image,image], return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "last_hidden_states = outputs.last_hidden_state\n",
    "list(last_hidden_states.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config._name_or_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SiglipMLP(nn.Module):\n",
    "    def __init__(self, input_dim, intermediate_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.pre_norm = nn.LayerNorm(input_dim)\n",
    "        self.proj = nn.Sequential(\n",
    "            nn.Linear(input_dim, intermediate_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(intermediate_dim, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:\n",
    "        hidden_states = self.pre_norm(hidden_states)\n",
    "        hidden_states = hidden_states+self.proj(hidden_states)\n",
    "        return hidden_states\n",
    "\n",
    "class VLContrastHead(nn.Module):\n",
    "    def __init__(self, vision_dimesion, text_dimension, device, target_dimension=512, linear=False):\n",
    "        super(VLContrastHead, self).__init__()\n",
    "        self.device = device if device else ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.linear = linear\n",
    "        if self.linear:\n",
    "            self.vision_mapping_network = nn.Linear(vision_dimesion, target_dimension)\n",
    "            self.text_mapping_network = nn.Linear(text_dimension, target_dimension)\n",
    "        else:\n",
    "            # self.vision_mapping_network = SiglipMLP(vision_dimesion, target_dimension, target_dimension)\n",
    "            # self.text_mapping_network = SiglipMLP(text_dimension, target_dimension, target_dimension)\n",
    "            self.vision_mapping_network = nn.Linear(vision_dimesion, target_dimension)\n",
    "            self.text_mapping_network = nn.Linear(text_dimension, target_dimension)\n",
    "            self.mapping_network = SiglipMLP(target_dimension, target_dimension, target_dimension)\n",
    "\n",
    "        self.vision_layer_norm = nn.LayerNorm(vision_dimesion)\n",
    "        self.text_layer_norm = nn.LayerNorm(text_dimension)\n",
    "        self.logit_scale = nn.Parameter(torch.randn(1))\n",
    "        self.logit_bias = nn.Parameter(torch.randn(1))\n",
    "\n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                torch.nn.init.xavier_uniform_(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    torch.nn.init.zeros_(module.bias)\n",
    "            elif isinstance(module, nn.LayerNorm):\n",
    "                torch.nn.init.ones_(module.weight)\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "\n",
    "        # Initialize logit_scale and logit_bias\n",
    "        logit_scale_init = torch.log(torch.tensor(10.0))\n",
    "        self.logit_scale.data.fill_(logit_scale_init)\n",
    "        self.logit_bias.data.fill_(torch.tensor(-10.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = VLContrastHead(512, 512, 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head.mapping_network.proj[2].bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 尝试释放显存\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# 查看显存使用情况\n",
    "print(torch.cuda.memory_allocated(0))\n",
    "print(torch.cuda.memory_reserved(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import Optional\n",
    "class StarMLP(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        output_dim: int,\n",
    "        intermediate_dim: Optional[int] = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        intermediate_dim = intermediate_dim if intermediate_dim is not None else output_dim\n",
    "        self.Wa = nn.Linear(input_dim, input_dim, bias=False)\n",
    "        self.Wb = nn.Linear(input_dim, input_dim, bias=False)\n",
    "        self.g = nn.Linear(input_dim, output_dim, bias=False)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        a = self.Wa(x)  # N x d\n",
    "        b = self.Wb(x)  # N x d\n",
    "        x = torch.einsum('bij,bj->bi', torch.sigmoid(a.unsqueeze(-1) * b.unsqueeze(1)), x)\n",
    "        x = self.g(x)\n",
    "\n",
    "        assert not torch.isnan(x).any(), \"Output contains NaN\"\n",
    "        assert not torch.isinf(x).any(), \"Output contains infinite values\"\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "networ = StarMLP(64, 128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 128])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(16, 64)\n",
    "networ(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openflamingo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
